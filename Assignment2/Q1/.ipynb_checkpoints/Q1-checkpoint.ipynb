{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7961fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries...\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "training_dir = \"/Users/sidharthagarwal/Desktop/assignments/ml774/Assignment2/Q1/part1_data/train\" #str(sys.argv[1])\n",
    "testing_dir  = \"/Users/sidharthagarwal/Desktop/assignments/ml774/Assignment2/Q1/part1_data/test\"  #str(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5b4c65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing variables..\n",
    "\n",
    "def restartModel():\n",
    "    wordFreq = {}\n",
    "    wordFreq[0] = {}\n",
    "    wordFreq[1] = {}\n",
    "\n",
    "    totalFreq = {}\n",
    "    totalFreq[0] = 0\n",
    "    totalFreq[1] = 0\n",
    "\n",
    "    totalDocs = {}\n",
    "    totalDocs[0] = 0\n",
    "    totalDocs[1] = 1\n",
    "\n",
    "    alpha = 1\n",
    "    posCloudText = \"\"\n",
    "    negCloudText = \"\"\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    vocabulary = 0\n",
    "    \n",
    "    return wordFreq,totalFreq,totalDocs,alpha,posCloudText,negCloudText,TP,FP,TN,FN,vocabulary\n",
    "\n",
    "wordFreq,totalFreq,totalDocs,alpha,posCloudText,negCloudText,TP,FP,TN,FN,vocabulary = restartModel()\n",
    "\n",
    "def resultAnalysis(TP,FP,TN,FN):\n",
    "    prec = TP/(TP+FP)\n",
    "    rec  = TP/(TP+FN)\n",
    "    print(\"The precision is : \"+str(prec))\n",
    "    print(\"The recall is : \"+str(rec))\n",
    "    print(\"The F1 score is : \"+str((2*prec*rec)/(prec+rec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a8132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def trainModel(path,label,wordFreq,totalFreq,totalDocs,preprocessing = False,featuring = False):\n",
    "    \n",
    "    listOfFiles = os.listdir(path)\n",
    "    for fileName in listOfFiles:\n",
    "        \n",
    "        file = open(os.path.join(path,fileName),\"r\")\n",
    "        text = file.read()\n",
    "        word_list = re.split(' |,|\\\\.|\\n|:|;|\"|\\'|`|{{|}}|[|]|\\)|\\(',text)\n",
    "        \n",
    "        new_word_list = []\n",
    "        for word in word_list:\n",
    "            \n",
    "            if preprocessing:\n",
    "                word = ps.stem(word.lower())\n",
    "                if word in stop_words:\n",
    "                    continue\n",
    "                \n",
    "            if word not in wordFreq[label]:\n",
    "                wordFreq[label][word] = 0\n",
    "                \n",
    "            wordFreq[label][word] += 1\n",
    "            totalFreq[label] += 1\n",
    "            new_word_list.append(word)\n",
    "        \n",
    "        if featuring:\n",
    "            prevWord = new_word_list[0]\n",
    "            for word in new_word_list[1:]:\n",
    "                bigram = prevWord + \" \" + word\n",
    "                prevWord = word\n",
    "                \n",
    "                if bigram not in wordFreq[label]:\n",
    "                    wordFreq[label][bigram] = 0\n",
    "                \n",
    "                wordFreq[label][bigram]  += 1\n",
    "                totalFreq[label][bigram] += 1\n",
    "        \n",
    "    totalDocs[label] += len(listOfFiles)\n",
    "\n",
    "trainModel(training_dir+\"/pos\",1,wordFreq,totalFreq,totalDocs)\n",
    "trainModel(training_dir+\"/neg\",0,wordFreq,totalFreq,totalDocs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training dataset: \n",
      "The accuracy is : 0.91628\n",
      "For testing dataset: \n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "\n",
    "def predictLabel(path,wordFreq,totalFreq,totalDocs,isPosCloud,preprocessing):\n",
    "    global posCloudText\n",
    "    global negCloudText\n",
    "    \n",
    "    file = open(path,\"r\")\n",
    "    text = file.read()\n",
    "    word_list = re.split(' |,|\\\\.|\\n|:|;|\"|\\'|`|{{|}}|[|]|\\)|\\(',text)\n",
    "    \n",
    "    positive_prob = 0\n",
    "    negative_prob = 0\n",
    "    \n",
    "    for word in word_list:\n",
    "        \n",
    "        if preprocessing:\n",
    "            word = ps.stem(word.lower())\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "        \n",
    "        #if isPosCloud:\n",
    "        #    posCloudText += word + \" \"\n",
    "        #else:\n",
    "        #    negCloudText += word + \" \"\n",
    "        \n",
    "        posFreq = alpha if word not in wordFreq[1] else wordFreq[1][word] + alpha\n",
    "        negFreq = alpha if word not in wordFreq[0] else wordFreq[0][word] + alpha\n",
    "        \n",
    "        positive_prob += math.log(posFreq) - math.log(totalFreq[1] + alpha*vocabulary)\n",
    "        negative_prob += math.log(negFreq) - math.log(totalFreq[0] + alpha*vocabulary)\n",
    "    \n",
    "    positive_prob +=  -1*math.log(totalDocs[0])\n",
    "    negative_prob +=  -1*math.log(totalDocs[1])\n",
    "    \n",
    "    if positive_prob>=negative_prob:\n",
    "        return 1\n",
    "    return 0\n",
    "        \n",
    "    \n",
    "def prediction(path,wordFreq,totalFreq,totalDocs,preprocessing = False):\n",
    "    global TP,TN,FP,FN\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pos_path = path + \"/pos\"\n",
    "    listOfPos = os.listdir(pos_path)\n",
    "    for fileName in listOfPos:\n",
    "        thisLabel = predictLabel(os.path.join(pos_path,fileName),wordFreq,totalFreq,totalDocs,True,preprocessing)\n",
    "        if(thisLabel==1):\n",
    "            correct += 1\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    total += len(listOfPos)\n",
    "    \n",
    "    neg_path = path + \"/neg\"\n",
    "    listOfNeg = os.listdir(neg_path)\n",
    "    for fileName in listOfNeg:\n",
    "        thisLabel = predictLabel(os.path.join(neg_path,fileName),wordFreq,totalFreq,totalDocs,False,preprocessing)\n",
    "        if(thisLabel==0):\n",
    "            correct += 1\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "    total += len(listOfNeg)\n",
    "    \n",
    "    print(\"The accuracy is : \"+str(correct/total))\n",
    "\n",
    "vocabulary = len(set(list(wordFreq[0].keys()) + list(wordFreq[1].keys())))\n",
    "print(\"For training dataset: \")\n",
    "prediction(training_dir,wordFreq,totalFreq,totalDocs)\n",
    "print(\"For testing dataset: \")\n",
    "prediction(testing_dir,wordFreq,totalFreq,totalDocs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cef53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordclouds\n",
    "#WordCloud(width = 800, height = 800, background_color ='white',stopwords = set(STOPWORDS),\n",
    "#          min_font_size = 10).generate(posCloudText)\n",
    "\n",
    "#WordCloud(width = 800, height = 800, background_color ='white',stopwords = set(STOPWORDS),\n",
    "#          min_font_size = 10).generate(negCloudText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qb\n",
    "\n",
    "totalPosB = len(os.listdir(testing_dir + \"/pos\"))\n",
    "totalNegB = len(os.listdir(testing_dir + \"/neg\"))\n",
    "\n",
    "print(\"For b.i the accuracy will be : 0.5\")\n",
    "print(\"For b.ii the accuracy will be : \"+str(totalPosB/(totalPosB+totalNegB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qc\n",
    "\n",
    "def printConfusion(TP,FP,TN,FN):\n",
    "    confDict = {\"1\":[TP,FN],\"0\":[FP,TN]}\n",
    "    df = pd.DataFrame(confDict)\n",
    "    df.index = [\"1\",\"0\"]\n",
    "    print(df)\n",
    "\n",
    "print(\"For part a: \")\n",
    "printConfusion(TP,FP,TN,FN)\n",
    "\n",
    "print(\"\\nFor part b random: \")\n",
    "printConfusion(totalPosB/2,totalPosB/2,totalNegB/2,totalNegB/2)\n",
    "\n",
    "print(\"\\nFor part b only positive: \")\n",
    "printConfusion(totalPosB,totalNegB,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa26dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Qd\n",
    "\n",
    "print(\"For part a: \")\n",
    "resultAnalysis(TP,FP,TN,FN)\n",
    "\n",
    "restartModel()\n",
    "trainModel(training_dir+\"/pos\",1,wordFreq,totalFreq,totalDocs,True)\n",
    "trainModel(training_dir+\"/neg\",0,wordFreq,totalFreq,totalDocs,True)\n",
    "\n",
    "vocabulary = len(set(list(wordFreq[0].keys()) + list(wordFreq[1].keys())))\n",
    "print(\"Accuracy For training dataset: \")\n",
    "prediction(training_dir,wordFreq,totalFreq,totalDocs,True)\n",
    "print(\"Accuracy For testing dataset: \")\n",
    "prediction(testing_dir,wordFreq,totalFreq,totalDocs,True)\n",
    "\n",
    "print(\"For part b: \")\n",
    "resultAnalysis(TP,FP,TN,FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db731bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qf\n",
    "#def resultAnalysis(TP,FP,TN,FN):\n",
    "#    prec = TP/(TP+FP)\n",
    "#    rec  = TP/(TP+FN)\n",
    "#    print(\"The precision is : \"+str(prev))\n",
    "#    print(\"The recall is : \"+str(rec))\n",
    "#    print(\"The F1 score is : \"+str((2*prec*rec)/(prec+rec)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
